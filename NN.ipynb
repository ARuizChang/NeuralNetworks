{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ARuizChang/NeuralNetworks/blob/main/NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlUZXPPOuk_w"
      },
      "source": [
        "#MNIST NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEaRd71nCuwV",
        "outputId": "7cfc0745-0898-4b22-ab65-88e32478c5be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-27 14:44:54--  https://raw.githubusercontent.com/ARuizChang/NeuralNetworks/refs/heads/main/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 76733040 (73M) [text/plain]\n",
            "Saving to: ‘train.csv.3’\n",
            "\n",
            "train.csv.3         100%[===================>]  73.18M   137MB/s    in 0.5s    \n",
            "\n",
            "2025-01-27 14:44:55 (137 MB/s) - ‘train.csv.3’ saved [76733040/76733040]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/ARuizChang/NeuralNetworks/refs/heads/main/train.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "tW3-EabmtN7y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.ndimage import rotate, shift, zoom\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Nxz1yuoSuKBe"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess data\n",
        "data = pd.read_csv('train.csv')\n",
        "data = np.array(data)\n",
        "m, n = data.shape\n",
        "np.random.shuffle(data)\n",
        "\n",
        "# Normalize data\n",
        "X = data[:, 1:] / 255.0\n",
        "Y = data[:, 0].astype(np.int32)  # Convert to integers\n",
        "\n",
        "# Split data into training and development sets\n",
        "X_dev = X[:1000]\n",
        "Y_dev = Y[:1000].astype(np.int32)  # Convert to integers\n",
        "X_train = X[1000:]\n",
        "Y_train = Y[1000:].astype(np.int32)  # Convert to integers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iagjqc-3uNel",
        "outputId": "b364f12f-5486-4fe5-bdf7-ff40d307d681"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 6, ..., 3, 3, 1], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "Y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD_U2c0puOM8"
      },
      "source": [
        "# Simple MNIST NN\n",
        "\n",
        "## Neural Network Architecture\n",
        "* Input layer $a^{[0]}$ will have 784 units corresponding to the 784 pixels in each 28x28 input image.\n",
        "* Hidden layer $a^{[1]}$ will have 100 units with ReLU activation.\n",
        "* Hidden layer $a^{[2]}$ will have 50 units with ReLU activation.\n",
        "* Hidden layer $a^{[3]}$ will have 20 units with ReLU activation.\n",
        "* Output layer $a^{[4]}$ will have 10 units with softmax activation.\n",
        "\n",
        "## Forward Pass\n",
        "$Z^{[1]} = W^{[1]} X + b^{[1]}$\n",
        "\n",
        "$A^{[1]} = g_{\\text{ReLU}}(Z^{[1]})$\n",
        "\n",
        "$Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}$\n",
        "\n",
        "$A^{[2]} = g_{\\text{ReLU}}(Z^{[2]})$\n",
        "\n",
        "$Z^{[3]} = W^{[3]} A^{[2]} + b^{[3]}$\n",
        "\n",
        "$A^{[3]} = g_{\\text{ReLU}}(Z^{[3]})$\n",
        "\n",
        "$Z^{[4]} = W^{[4]} A^{[3]} + b^{[4]}$\n",
        "\n",
        "$A^{[4]} = g_{\\text{softmax}}(Z^{[4]})$\n",
        "\n",
        "## Backward Propagation\n",
        "$dZ^{[4]} = A^{[4]} - Y$\n",
        "\n",
        "$dW^{[4]} = \\frac{1}{m} dZ^{[4]} A^{[3]T}$\n",
        "\n",
        "$dB^{[4]} = \\frac{1}{m} \\sum dZ^{[4]}$\n",
        "\n",
        "$dZ^{[3]} = W^{[4]T} dZ^{[4]} \\cdot g^{[3]\\prime} (Z^{[3]})$\n",
        "\n",
        "$dW^{[3]} = \\frac{1}{m} dZ^{[3]} A^{[2]T}$\n",
        "\n",
        "$dB^{[3]} = \\frac{1}{m} \\sum dZ^{[3]}$\n",
        "\n",
        "$dZ^{[2]} = W^{[3]T} dZ^{[3]} \\cdot g^{[2]\\prime} (Z^{[2]})$\n",
        "\n",
        "$dW^{[2]} = \\frac{1}{m} dZ^{[2]} A^{[1]T}$\n",
        "\n",
        "$dB^{[2]} = \\frac{1}{m} \\sum dZ^{[2]}$\n",
        "\n",
        "$dZ^{[1]} = W^{[2]T} dZ^{[2]} \\cdot g^{[1]\\prime} (Z^{[1]})$\n",
        "\n",
        "$dW^{[1]} = \\frac{1}{m} dZ^{[1]} A^{[0]T}$\n",
        "\n",
        "$dB^{[1]} = \\frac{1}{m} \\sum dZ^{[1]}$\n",
        "\n",
        "## Parameter Updates\n",
        "$W^{[4]} := W^{[4]} - \\alpha dW^{[4]}$\n",
        "\n",
        "$b^{[4]} := b^{[4]} - \\alpha db^{[4]}$\n",
        "\n",
        "$W^{[3]} := W^{[3]} - \\alpha dW^{[3]}$\n",
        "\n",
        "$b^{[3]} := b^{[3]} - \\alpha db^{[3]}$\n",
        "\n",
        "$W^{[2]} := W^{[2]} - \\alpha dW^{[2]}$\n",
        "\n",
        "$b^{[2]} := b^{[2]} - \\alpha db^{[2]}$\n",
        "\n",
        "$W^{[1]} := W^{[1]} - \\alpha dW^{[1]}$\n",
        "\n",
        "$b^{[1]} := b^{[1]} - \\alpha db^{[1]}$\n",
        "\n",
        "## ReLU\n",
        "$F(x) = \\max(0, x)$\n",
        "\n",
        "## Softmax\n",
        "$\\text{softmax}(x_i) = \\frac{e^{x_i}}{\\sum_{j=1}^{n} e^{x_j}}$\n",
        "\n",
        "## Variables and Shapes\n",
        "\n",
        "### Forward Pass\n",
        "* $A^{[0]} = X$: 784 x m\n",
        "* $Z^{[1]} \\sim A^{[1]}$: 100 x m\n",
        "* $W^{[1]}$: 100 x 784 (as $W^{[1]} A^{[0]} \\sim Z^{[1]}$)\n",
        "* $b^{[1]}$: 100 x 1\n",
        "* $Z^{[2]} \\sim A^{[2]}$: 50 x m\n",
        "* $W^{[2]}$: 50 x 100 (as $W^{[2]} A^{[1]} \\sim Z^{[2]}$)\n",
        "* $b^{[2]}$: 50 x 1\n",
        "* $Z^{[3]} \\sim A^{[3]}$: 20 x m\n",
        "* $W^{[3]}$: 20 x 50 (as $W^{[3]} A^{[2]} \\sim Z^{[3]}$)\n",
        "* $b^{[3]}$: 20 x 1\n",
        "* $Z^{[4]} \\sim A^{[4]}$: 10 x m\n",
        "* $W^{[4]}$: 10 x 20 (as $W^{[4]} A^{[3]} \\sim Z^{[4]}$)\n",
        "* $b^{[4]}$: 10 x 1\n",
        "\n",
        "### Backpropagation\n",
        "* $dZ^{[4]}$: 10 x m ($\\sim A^{[4]}$)\n",
        "* $dW^{[4]}$: 10 x 20\n",
        "* $dB^{[4]}$: 10 x 1\n",
        "* $dZ^{[3]}$: 20 x m ($\\sim A^{[3]}$)\n",
        "* $dW^{[3]}$: 20 x 50\n",
        "* $dB^{[3]}$: 20 x 1\n",
        "* $dZ^{[2]}$: 50 x m ($\\sim A^{[2]}$)\n",
        "* $dW^{[2]}$: 50 x 100\n",
        "* $dB^{[2]}$: 50 x 1\n",
        "* $dZ^{[1]}$: 100 x m ($\\sim A^{[1]}$)\n",
        "* $dW^{[1]}$: 100 x 784\n",
        "* $dB^{[1]}$: 100 x 1\n",
        "\n",
        "# Adam Optimizer\n",
        "\n",
        "Initialize the first moment vector $m$ and the second moment vector $v$ to zero:\n",
        "$$m_0 = 0, \\quad v_0 = 0$$\n",
        "\n",
        "At each time step $t$, compute the gradients $g_t$ of the loss function with respect to the parameters:\n",
        "$$g_t = \\nabla_{\\theta} J(\\theta_t)$$\n",
        "\n",
        "Update the biased first moment estimate:\n",
        "$$m_t = \\beta_1 \\cdot m_{t-1} + (1 - \\beta_1) \\cdot g_t$$\n",
        "\n",
        "Update the biased second moment estimate:\n",
        "$$v_t = \\beta_2 \\cdot v_{t-1} + (1 - \\beta_2) \\cdot g_t^2$$\n",
        "\n",
        "Compute bias-corrected first moment estimate:\n",
        "$$\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}$$\n",
        "\n",
        "Compute bias-corrected second moment estimate:\n",
        "$$\\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}$$\n",
        "\n",
        "Update the parameters:\n",
        "$$\\theta_t = \\theta_{t-1} - \\alpha \\cdot \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}$$\n",
        "\n",
        "### Parameters:\n",
        "- $\\alpha$: Learning rate (default is 0.001)\n",
        "- $\\beta_1$: Exponential decay rate for the first moment estimates (default is 0.9)\n",
        "- $\\beta_2$: Exponential decay rate for the second moment estimates (default is 0.999)\n",
        "- $\\epsilon$: Small constant for numerical stability (default is 1e-8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "h8ylCS7puU-h"
      },
      "outputs": [],
      "source": [
        "def one_hot(Y):\n",
        "    num_classes = int(np.max(Y)) + 1\n",
        "    one_hot_Y = np.zeros((Y.shape[0], num_classes))\n",
        "    one_hot_Y[np.arange(Y.shape[0]), Y.astype(np.int32)] = 1\n",
        "    return one_hot_Y.T  # Transpose to get shape (num_classes, m)\n",
        "\n",
        "# Augmentation functions\n",
        "def random_rotation(image, angle_range=(-15, 15)):\n",
        "    angle = np.random.uniform(angle_range[0], angle_range[1])\n",
        "    return rotate(image, angle, reshape=False, mode='nearest')\n",
        "\n",
        "def random_shift(image, shift_range=(-2, 2)):\n",
        "    shift_values = [np.random.uniform(shift_range[0], shift_range[1]) for _ in range(2)]\n",
        "    return shift(image, shift_values, mode='nearest')\n",
        "\n",
        "def random_zoom(image, zoom_range=(0.9, 1.1)):\n",
        "    zoom_factor = np.random.uniform(zoom_range[0], zoom_range[1])\n",
        "    zoomed_image = zoom(image, zoom_factor, order=1)\n",
        "    return zoomed_image\n",
        "\n",
        "def resize_image(image, shape=(28, 28)):\n",
        "    zoom_factors = (shape[0] / image.shape[0], shape[1] / image.shape[1])\n",
        "    return zoom(image, zoom_factors, order=1)\n",
        "\n",
        "def augment_image(image):\n",
        "    image = image.reshape(28, 28)\n",
        "    image = random_rotation(image)\n",
        "    image = random_shift(image)\n",
        "    image = random_zoom(image)\n",
        "    image = resize_image(image, (28, 28))  # Ensure shape remains consistent\n",
        "    return image.flatten()\n",
        "\n",
        "def augment_data(X):\n",
        "    augmented_X = np.zeros_like(X)\n",
        "    for i in range(X.shape[0]):\n",
        "        augmented_X[i] = augment_image(X[i])\n",
        "    return augmented_X\n",
        "\n",
        "# Initialize parameters\n",
        "def init_params():\n",
        "    W1 = np.random.randn(100, 784) * 0.01\n",
        "    b1 = np.zeros((100, 1))\n",
        "    W2 = np.random.randn(50, 100) * 0.01\n",
        "    b2 = np.zeros((50, 1))\n",
        "    W3 = np.random.randn(20, 50) * 0.01\n",
        "    b3 = np.zeros((20, 1))\n",
        "    W4 = np.random.randn(10, 20) * 0.01\n",
        "    b4 = np.zeros((10, 1))\n",
        "    return W1, b1, W2, b2, W3, b3, W4, b4\n",
        "\n",
        "# Activation functions\n",
        "def ReLU(Z):\n",
        "    return np.maximum(0, Z)\n",
        "\n",
        "def softmax(Z):\n",
        "    expZ = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n",
        "    return expZ / expZ.sum(axis=0, keepdims=True)\n",
        "\n",
        "def ReLU_derivative(Z):\n",
        "    return Z > 0\n",
        "\n",
        "# Dropout\n",
        "def dropout(A, keep_prob):\n",
        "    D = np.random.rand(*A.shape) < keep_prob\n",
        "    A = A * D\n",
        "    A = A / keep_prob\n",
        "    return A, D\n",
        "\n",
        "# Forward pass\n",
        "def forward_pass(X, W1, b1, W2, b2, W3, b3, W4, b4, keep_prob=0.8):\n",
        "    Z1 = W1.dot(X) + b1\n",
        "    A1 = ReLU(Z1)\n",
        "    A1, D1 = dropout(A1, keep_prob)\n",
        "\n",
        "    Z2 = W2.dot(A1) + b2\n",
        "    A2 = ReLU(Z2)\n",
        "    A2, D2 = dropout(A2, keep_prob)\n",
        "\n",
        "    Z3 = W3.dot(A2) + b3\n",
        "    A3 = ReLU(Z3)\n",
        "    A3, D3 = dropout(A3, keep_prob)\n",
        "\n",
        "    Z4 = W4.dot(A3) + b4\n",
        "    A4 = softmax(Z4)\n",
        "\n",
        "    return Z1, A1, D1, Z2, A2, D2, Z3, A3, D3, Z4, A4\n",
        "\n",
        "def backward_prop(X, Y, Z1, A1, D1, Z2, A2, D2, Z3, A3, D3, Z4, A4, W2, W3, W4, keep_prob=0.8):\n",
        "    # Ensure Y is a 2D array\n",
        "    if len(Y.shape) == 1:\n",
        "        Y = Y.reshape(1, -1)\n",
        "\n",
        "    # Get the number of examples\n",
        "    m = Y.shape[1]\n",
        "\n",
        "    # Backward propagation computations\n",
        "    dZ4 = A4 - Y\n",
        "    dW4 = 1 / m * dZ4.dot(A3.T)\n",
        "    db4 = 1 / m * np.sum(dZ4, axis=1, keepdims=True)\n",
        "\n",
        "    dA3 = W4.T.dot(dZ4)\n",
        "    dA3 = dA3 * D3\n",
        "    dA3 = dA3 / keep_prob\n",
        "\n",
        "    dZ3 = dA3 * (1 - np.power(A3, 2))\n",
        "    dW3 = 1 / m * dZ3.dot(A2.T)\n",
        "    db3 = 1 / m * np.sum(dZ3, axis=1, keepdims=True)\n",
        "\n",
        "    dA2 = W3.T.dot(dZ3)\n",
        "    dA2 = dA2 * D2\n",
        "    dA2 = dA2 / keep_prob\n",
        "\n",
        "    dZ2 = dA2 * (1 - np.power(A2, 2))\n",
        "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
        "    db2 = 1 / m * np.sum(dZ2, axis=1, keepdims=True)\n",
        "\n",
        "    dA1 = W2.T.dot(dZ2)\n",
        "    dA1 = dA1 * D1\n",
        "    dA1 = dA1 / keep_prob\n",
        "\n",
        "    dZ1 = dA1 * (1 - np.power(A1, 2))\n",
        "    dW1 = 1 / m * dZ1.dot(X.T)\n",
        "    db1 = 1 / m * np.sum(dZ1, axis=1, keepdims=True)\n",
        "\n",
        "    return dW1, db1, dW2, db2, dW3, db3, dW4, db4\n",
        "\n",
        "\n",
        "\n",
        "def update_params(W1, b1, W2, b2, W3, b3, W4, b4, dW1, db1, dW2, db2, dW3, db3, dW4, db4, alpha):\n",
        "    W1 = W1 - alpha * dW1\n",
        "    b1 = b1 - alpha * db1\n",
        "    W2 = W2 - alpha * dW2\n",
        "    b2 = b2 - alpha * db2\n",
        "    W3 = W3 - alpha * dW3\n",
        "    b3 = b3 - alpha * db3\n",
        "    W4 = W4 - alpha * dW4\n",
        "    b4 = b4 - alpha * db4\n",
        "    return W1, b1, W2, b2, W3, b3, W4, b4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "D894jIhQ3Gnt"
      },
      "outputs": [],
      "source": [
        "X_train_augmented = augment_data(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "8z8-pUQPuY4k"
      },
      "outputs": [],
      "source": [
        "# Gradient descent with Adam optimizer and learning rate scheduling\n",
        "def gradient_descent(X, Y, alpha, iterations, decay_rate=0.1, decay_step=100):\n",
        "    W1, b1, W2, b2, W3, b3, W4, b4 = init_params()\n",
        "    mW = [np.zeros_like(W1), np.zeros_like(W2), np.zeros_like(W3), np.zeros_like(W4)]\n",
        "    mb = [np.zeros_like(b1), np.zeros_like(b2), np.zeros_like(b3), np.zeros_like(b4)]\n",
        "    vW = [np.zeros_like(W1), np.zeros_like(W2), np.zeros_like(W3), np.zeros_like(W4)]\n",
        "    vb = [np.zeros_like(b1), np.zeros_like(b2), np.zeros_like(b3), np.zeros_like(b4)]\n",
        "    beta1, beta2, epsilon = 0.9, 0.999, 1e-8\n",
        "    t = 0\n",
        "\n",
        "    for i in range(iterations):\n",
        "        t += 1\n",
        "        Z1, A1, D1, Z2, A2, D2, Z3, A3, D3, Z4, A4 = forward_pass(X.T, W1, b1, W2, b2, W3, b3, W4, b4)\n",
        "        dW1, db1, dW2, db2, dW3, db3, dW4, db4 = backward_prop(X.T, Y, Z1, A1, D1, Z2, A2, D2, Z3, A3, D3, Z4, A4, W2, W3, W4)\n",
        "        W1, b1, W2, b2, W3, b3, W4, b4 = update_params(W1, b1, W2, b2, W3, b3, W4, b4, dW1, db1, dW2, db2, dW3, db3, dW4, db4, alpha)\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        if i % decay_step == 0 and i != 0:\n",
        "            alpha = alpha * (1 / (1 + decay_rate * i))\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            predictions = np.argmax(A4, axis=0)\n",
        "            accuracy = np.mean(predictions == np.argmax(Y, axis=0))\n",
        "            print(f\"Iteration {i}, Accuracy: {accuracy}, Learning Rate: {alpha}\")\n",
        "    return W1, b1, W2, b2, W3, b3, W4, b4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "8G0NtgZiucD6",
        "outputId": "607b5ddd-1eb8-45b5-a925-908615656bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Accuracy: 0.04624390243902439, Learning Rate: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-8ccde07dfc5f>:113: RuntimeWarning: overflow encountered in multiply\n",
            "  dZ2 = dA2 * (1 - np.power(A2, 2))\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "<ipython-input-27-8ccde07dfc5f>:118: RuntimeWarning: invalid value encountered in multiply\n",
            "  dA1 = dA1 * D1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 100, Accuracy: 0.0, Learning Rate: 0.009090909090909092\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-dd73d992803b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_augmented\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-e2d9a70ebfea>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(X, Y, alpha, iterations, decay_rate, decay_step)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mZ1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mdW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-8ccde07dfc5f>\u001b[0m in \u001b[0;36mbackward_prop\u001b[0;34m(X, Y, Z1, A1, D1, Z2, A2, D2, Z3, A3, D3, Z4, A4, W2, W3, W4, keep_prob)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mdA2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdA2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mdZ2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdA2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0mdW2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdZ2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mdb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "W1, b1, W2, b2, W3, b3, W4, b4 = gradient_descent(X_train_augmented, Y_train, alpha=0.10, iterations=1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRTfYN7Tuej4"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "Z1, A1, D1, Z2, A2, D2, Z3, A3, D3, Z4, A4 = forward_pass(X_dev.T, W1, b1, W2, b2, W3, b3, W4, b4, keep_prob=1.0)  # No dropout during evaluation\n",
        "predictions = np.argmax(A4, axis=0)\n",
        "accuracy = np.mean(predictions == np.argmax(Y_dev, axis=0))\n",
        "print(f\"Development set accuracy: {accuracy}\")\n",
        "\n",
        "def display_prediction(index):\n",
        "    plt.imshow(X_dev[index].reshape(28, 28), cmap='gray')\n",
        "\n",
        "    # Si Y_dev es 1D\n",
        "    if len(Y_dev.shape) == 1:\n",
        "        plt.title(f\"Prediction: {predictions[index]}, True Label: {Y_dev[index]}\")\n",
        "    # Si Y_dev es 2D (one-hot encoding)\n",
        "    elif len(Y_dev.shape) == 2:\n",
        "        plt.title(f\"Prediction: {predictions[index]}, True Label: {np.argmax(Y_dev[index])}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAFvUR_nuggg"
      },
      "outputs": [],
      "source": [
        "display_prediction(0)\n",
        "display_prediction(1)\n",
        "display_prediction(2)\n",
        "display_prediction(3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1qb0gcwx0y7Ov317eUcll6149WvPIjBut",
      "authorship_tag": "ABX9TyN4JtWDR0MqDR7F3QWPmBSS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}